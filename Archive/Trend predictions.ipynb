{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e062bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7d529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jensk/code/JensKlug/zillows_real_estate/raw_data/HouseTS.csv')\n",
    "\n",
    "df = df.sort_values(['city', 'zipcode', 'date']).reset_index(drop=True)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "train = df[df.date.dt.year<2023]\n",
    "test = df[df.date.dt.year>2022]\n",
    "\n",
    "grouped_train = train.groupby(['city', 'zipcode'])\n",
    "grouped_test = test.groupby(['city', 'zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae7addc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d78755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nts_train = pd.DataFrame()\\nts_test = pd.DataFrame()\\n\\n\\nls = [1,3,6,12]\\n\\ni = 2\\n\\n#for i in ls:\\nts_train[f'target_profitable_{i}m'] = (grouped_train['price'].shift(-i) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\\nts_train['zipcode'] = grouped_train['zipcode'].shift(0).astype('object') # but remains still an integer...\\n\\n\\nnumeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\\n\\nfor feature in numeric_column_names:\\n    for lag in range(1, 4):  # 1 to 3 months\\n        ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ts_train = pd.DataFrame()\n",
    "ts_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "ls = [1,3,6,12]\n",
    "\n",
    "i = 2\n",
    "\n",
    "#for i in ls:\n",
    "ts_train[f'target_profitable_{i}m'] = (grouped_train['price'].shift(-i) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\n",
    "ts_train['zipcode'] = grouped_train['zipcode'].shift(0).astype('object') # but remains still an integer...\n",
    "\n",
    "\n",
    "numeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "for feature in numeric_column_names:\n",
    "    for lag in range(1, 4):  # 1 to 3 months\n",
    "        ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f574d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts_train #type(ts_train['zipcode'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c097ef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42416/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_42416/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n"
     ]
    }
   ],
   "source": [
    "ts_train = pd.DataFrame()\n",
    "ts_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "ls = [1,3,6,12]\n",
    "\n",
    "i = 1\n",
    "\n",
    "#for i in ls:\n",
    "ts_train[f'target_profitable_{i}m'] = (grouped_train['price'].shift(-i) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\n",
    "ts_train['zipcode'] = grouped_train['zipcode'].shift(0)# .astype('object') # but remains still an integer...\n",
    "numeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "for feature in numeric_column_names:\n",
    "    for lag in range(1, 4):  # 1 to 3 months\n",
    "        ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
    "\n",
    "ts_train = ts_train.dropna().reset_index(drop=True)\n",
    "\n",
    "X_train = ts_train.drop(columns=[f'target_profitable_{i}m'])\n",
    "y_train = ts_train[f'target_profitable_{i}m']\n",
    "\n",
    "\n",
    "ts_test[f'target_profitable_{i}m'] = (grouped_test['price'].shift(-i) > 1.02 * grouped_test['price'].shift(0)).astype(int)\n",
    "ts_test['zipcode'] = grouped_test['zipcode'].shift(0)# .astype('object') # but remains still an integer...\n",
    "numeric_column_names = test.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "for feature in numeric_column_names:\n",
    "    for lag in range(1, 4):  # 1 to 6 months\n",
    "        ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
    "\n",
    "ts_test = ts_test.dropna().reset_index(drop=True)\n",
    "\n",
    "X_test = ts_test.drop(columns=[f'target_profitable_{i}m'])\n",
    "y_test = ts_test[f'target_profitable_{i}m']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = SGDClassifier(loss='log_loss')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "np.savetxt(f\"output_{i}m.csv\", y_pred, delimiter=\",\", header=f\"target_-{i}m\", comments='')\n",
    "\n",
    "del y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8c434f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        30002\n",
       "1        30002\n",
       "2        30002\n",
       "3        30002\n",
       "4        30002\n",
       "         ...  \n",
       "56029    34698\n",
       "56030    34698\n",
       "56031    34698\n",
       "56032    34698\n",
       "56033    34698\n",
       "Name: zipcode, Length: 56034, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipcode_identifier = ts_test['zipcode']\n",
    "zipcode_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155b76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba8787f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jensk/code/JensKlug/zillows_real_estate/notebooks'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d2a9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_-1m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56029</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56030</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56031</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56032</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56033</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56034 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_-1m\n",
       "0             0.0\n",
       "1             0.0\n",
       "2             0.0\n",
       "3             0.0\n",
       "4             0.0\n",
       "...           ...\n",
       "56029         0.0\n",
       "56030         0.0\n",
       "56031         0.0\n",
       "56032         0.0\n",
       "56033         0.0\n",
       "\n",
       "[56034 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1 = pd.read_csv('output_1m.csv')\n",
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1ad6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_-2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56029</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56030</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56031</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56032</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56033</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56034 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_-2m\n",
       "0             0.0\n",
       "1             0.0\n",
       "2             0.0\n",
       "3             0.0\n",
       "4             0.0\n",
       "...           ...\n",
       "56029         0.0\n",
       "56030         0.0\n",
       "56031         0.0\n",
       "56032         0.0\n",
       "56033         0.0\n",
       "\n",
       "[56034 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2 = pd.read_csv('output_2m.csv')\n",
    "output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d17ba0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>target_-1m</th>\n",
       "      <th>target_-2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56029</th>\n",
       "      <td>34698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56030</th>\n",
       "      <td>34698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56031</th>\n",
       "      <td>34698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56032</th>\n",
       "      <td>34698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56033</th>\n",
       "      <td>34698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56034 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       zipcode  target_-1m  target_-2m\n",
       "0        30002         0.0         0.0\n",
       "1        30002         0.0         0.0\n",
       "2        30002         0.0         0.0\n",
       "3        30002         0.0         0.0\n",
       "4        30002         0.0         0.0\n",
       "...        ...         ...         ...\n",
       "56029    34698         0.0         0.0\n",
       "56030    34698         0.0         0.0\n",
       "56031    34698         0.0         0.0\n",
       "56032    34698         0.0         0.0\n",
       "56033    34698         0.0         0.0\n",
       "\n",
       "[56034 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.concat([zipcode_identifier, output_1, output_2], axis=1)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81c28809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_-1m  target_-2m\n",
       "0.000000    0.000000      5227\n",
       "            0.111111       279\n",
       "            0.222222       155\n",
       "            0.333333       143\n",
       "            0.444444        95\n",
       "            0.555556        84\n",
       "            0.666667        72\n",
       "            1.000000        65\n",
       "            0.777778        56\n",
       "            0.888889        43\n",
       "0.111111    0.555556         4\n",
       "            0.222222         1\n",
       "            0.777778         1\n",
       "            0.888889         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_result = df_combined.groupby(['zipcode']).mean()\n",
    "grouped_result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf9a6087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ts_train = pd.DataFrame()\\nts_test = pd.DataFrame()\\n\\n#ls = [1,3,6,12]\\n\\n\\n\\n#for i in ls:\\nts_train['target_profitable_3m'] = (grouped_train['price'].shift(-6) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\\n\\nnumeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\\n\\nfor feature in numeric_column_names:\\n    for lag in range(1, 4):  # 1 to 3 months\\n        ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\\n\\nts_train = ts_train.dropna().reset_index(drop=True)\\n\\nX_train = ts_train.drop(columns=['target_profitable_3m'])\\ny_train = ts_train['target_profitable_3m']\\n\\n\\nts_test['target_profitable_3m'] = (grouped_test['price'].shift(-6) > 1.02 * grouped_test['price'].shift(0)).astype(int)\\n\\nnumeric_column_names = test.select_dtypes(include='number').columns # drop the lags of zipcode\\n\\nfor feature in numeric_column_names:\\n    for lag in range(1, 4):  # 1 to 6 months\\n        ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\\n\\nts_test = ts_test.dropna().reset_index(drop=True)\\n\\nX_test = ts_test.drop(columns=['target_profitable_3m'])\\ny_test = ts_test['target_profitable_3m']\\n\\nscaler = MinMaxScaler()\\nscaler.fit(X_train)\\nX_train_scaled = scaler.transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\nmodel = SGDClassifier(loss='log_loss')\\nmodel.fit(X_train_scaled, y_train)\\n\\ny_pred = model.predict(X_test_scaled)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ts_train = pd.DataFrame()\n",
    "ts_test = pd.DataFrame()\n",
    "\n",
    "#ls = [1,3,6,12]\n",
    "\n",
    "\n",
    "\n",
    "#for i in ls:\n",
    "ts_train['target_profitable_3m'] = (grouped_train['price'].shift(-6) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\n",
    "\n",
    "numeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "for feature in numeric_column_names:\n",
    "    for lag in range(1, 4):  # 1 to 3 months\n",
    "        ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
    "\n",
    "ts_train = ts_train.dropna().reset_index(drop=True)\n",
    "\n",
    "X_train = ts_train.drop(columns=['target_profitable_3m'])\n",
    "y_train = ts_train['target_profitable_3m']\n",
    "\n",
    "\n",
    "ts_test['target_profitable_3m'] = (grouped_test['price'].shift(-6) > 1.02 * grouped_test['price'].shift(0)).astype(int)\n",
    "\n",
    "numeric_column_names = test.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "for feature in numeric_column_names:\n",
    "    for lag in range(1, 4):  # 1 to 6 months\n",
    "        ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
    "\n",
    "ts_test = ts_test.dropna().reset_index(drop=True)\n",
    "\n",
    "X_test = ts_test.drop(columns=['target_profitable_3m'])\n",
    "y_test = ts_test['target_profitable_3m']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = SGDClassifier(loss='log_loss')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ts_train = pd.DataFrame()\\nts_test = pd.DataFrame()\\n\\n\\nls = [1,3,6,12]\\n\\nfor i in ls:\\n    ts_train[f\\'target_profitable_{i}m\\'] = (grouped_train[\\'price\\'].shift(-i) > 1.02 * grouped_train[\\'price\\'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\\n\\n    numeric_column_names = train.select_dtypes(include=\\'number\\').columns # drop the lags of zipcode\\n\\n    for feature in numeric_column_names:\\n        for lag in range(1, 4):  # 1 to 3 months\\n            ts_train[f\\'{feature}_{lag}m\\'] = grouped_train[f\\'{feature}\\'].shift(lag)\\n\\n    ts_train = ts_train.dropna().reset_index(drop=True)\\n\\n    X_train = ts_train.drop(columns=[f\\'target_profitable_{i}m\\'])\\n    y_train = ts_train[f\\'target_profitable_{i}m\\']\\n\\n\\n    ts_test[f\\'target_profitable_{i}m\\'] = (grouped_test[\\'price\\'].shift(-i) > 1.02 * grouped_test[\\'price\\'].shift(0)).astype(int)\\n\\n    numeric_column_names = test.select_dtypes(include=\\'number\\').columns # drop the lags of zipcode\\n\\n    for feature in numeric_column_names:\\n        for lag in range(1, 4):  # 1 to 6 months\\n            ts_test[f\\'{feature}_{lag}m\\'] = grouped_test[f\\'{feature}\\'].shift(lag)\\n\\n    ts_test = ts_test.dropna().reset_index(drop=True)\\n\\n    X_test = ts_test.drop(columns=[f\\'target_profitable_{i}m\\'])\\n    y_test = ts_test[f\\'target_profitable_{i}m\\']\\n\\n    scaler = MinMaxScaler()\\n    scaler.fit(X_train)\\n    X_train_scaled = scaler.transform(X_train)\\n    X_test_scaled = scaler.transform(X_test)\\n\\n    model = SGDClassifier(loss=\\'log_loss\\')\\n    model.fit(X_train_scaled, y_train)\\n\\n    y_pred = model.predict(X_test_scaled)\\n\\n    np.savetxt(f\"output_{i}m.csv\", y_pred, delimiter=\",\", header=f\"target_-{i}m\", comments=\\'\\')\\n\\n    del y_pred\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ts_train = pd.DataFrame()\n",
    "ts_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "ls = [1,3,6,12]\n",
    "\n",
    "for i in ls:\n",
    "    ts_train[f'target_profitable_{i}m'] = (grouped_train['price'].shift(-i) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\n",
    "\n",
    "    numeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "    for feature in numeric_column_names:\n",
    "        for lag in range(1, 4):  # 1 to 3 months\n",
    "            ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
    "\n",
    "    ts_train = ts_train.dropna().reset_index(drop=True)\n",
    "\n",
    "    X_train = ts_train.drop(columns=[f'target_profitable_{i}m'])\n",
    "    y_train = ts_train[f'target_profitable_{i}m']\n",
    "\n",
    "\n",
    "    ts_test[f'target_profitable_{i}m'] = (grouped_test['price'].shift(-i) > 1.02 * grouped_test['price'].shift(0)).astype(int)\n",
    "\n",
    "    numeric_column_names = test.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "    for feature in numeric_column_names:\n",
    "        for lag in range(1, 4):  # 1 to 6 months\n",
    "            ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
    "\n",
    "    ts_test = ts_test.dropna().reset_index(drop=True)\n",
    "\n",
    "    X_test = ts_test.drop(columns=[f'target_profitable_{i}m'])\n",
    "    y_test = ts_test[f'target_profitable_{i}m']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = SGDClassifier(loss='log_loss')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    np.savetxt(f\"output_{i}m.csv\", y_pred, delimiter=\",\", header=f\"target_-{i}m\", comments='')\n",
    "\n",
    "    del y_pred\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zillows_real_estate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
