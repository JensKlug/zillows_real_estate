{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "f06a3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "import pgeocode\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "827ca251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read HouseTS.csv into area_df\n",
    "area_df = pd.read_csv('../raw_data/HouseTS.csv')\n",
    "\n",
    "# Read realtor-data.csv into house_df\n",
    "house_df = pd.read_csv('../raw_data/realtor-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "17c4ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of unique zipcodes in area_df\n",
    "unique_zipcodes_area_df = area_df['zipcode'].unique().tolist()\n",
    "\n",
    "# Filter house_df by unique_zipcoes_area_df\n",
    "house_df = house_df[house_df['zip_code'].isin(unique_zipcodes_area_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "154cda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Drop columns 'brokered_by', 'status'\n",
    "    df = df.drop(columns=['brokered_by', 'status'])\n",
    "\n",
    "     # Drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Drop columns 'street', 'city', 'state' and 'prev_sold_date'\n",
    "    df = df.drop(columns=['street', 'city', 'state', 'prev_sold_date'])\n",
    "\n",
    "    # Drop rows with NaN values from 'price'\n",
    "    df = df.dropna(subset=['price'])\n",
    "\n",
    "    # Create list where 'bed' & 'bath' & 'house_size' are NaN\n",
    "    nan_values = df[\n",
    "        (pd.isna(df['bed'])) &\n",
    "        (pd.isna(df['bath'])) &\n",
    "        (pd.isna(df['house_size']))\n",
    "    ]\n",
    "\n",
    "    # Filter out rows that are in nan_values because we assume they are land sales\n",
    "    df = df[~df.index.isin(nan_values.index)]\n",
    "\n",
    "    # Impute missing data\n",
    "    df['bed'] = df['bed'].fillna(df['bed'].median())\n",
    "    df['bath'] = df['bath'].fillna(df['bath'].median())\n",
    "    df['house_size'] = df['house_size'].fillna(df['house_size'].median())\n",
    "    df['acre_lot'] = df['acre_lot'].fillna(0)\n",
    "\n",
    "    # Step 2: Calculate PPSF for each row\n",
    "    df['ppsf'] = df['price'] / df['house_size']\n",
    "\n",
    "    # Step 3: Calculate median PPSF per zip_code\n",
    "    ppsf_median = df.groupby('zip_code')['ppsf'].median().reset_index(name='ppsf_zipcode')\n",
    "\n",
    "    # Step 4: Merge median PPSF back to df\n",
    "    df = df.merge(ppsf_median, on='zip_code', how='left')\n",
    "\n",
    "    # Drop temporary ppsf column\n",
    "    df = df.drop(columns=['ppsf'])\n",
    "\n",
    "    # Calculate boundaries for 'price', 'acre_lot', 'house_size', 'ppsf_zipcode'\n",
    "    lower_price = df['price'].quantile(0.03)\n",
    "    upper_price = df['price'].quantile(0.97)\n",
    "    upper_house_size = df['house_size'].quantile(0.99)\n",
    "    lower_acre_lot = df['acre_lot'].quantile(0.01)\n",
    "    upper_acre_lot = df['acre_lot'].quantile(0.99)\n",
    "    lower_ppsf_zipcode = df['ppsf_zipcode'].quantile(0.03)\n",
    "    upper_ppsf_zipcode = df['ppsf_zipcode'].quantile(0.97)\n",
    "\n",
    "    # Apply boundaries to df\n",
    "    df = df[\n",
    "        (df['price'] > lower_price) &\n",
    "        (df['price'] < upper_price) &\n",
    "        (df['bed'] < 14) &\n",
    "        (df['bath'] < 12) &\n",
    "        (df['house_size'] < upper_house_size) &\n",
    "        (df['acre_lot'] > lower_acre_lot) &\n",
    "        (df['acre_lot'] < upper_acre_lot) &\n",
    "        (df['ppsf_zipcode'] > lower_ppsf_zipcode) &\n",
    "        (df['ppsf_zipcode'] < upper_ppsf_zipcode)\n",
    "        ]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "56ea42f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean df\n",
    "cleaned_house_df = clean_data(house_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "dcc6b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 608684 entries, 0 to 854410\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   price         608684 non-null  float64\n",
      " 1   bed           608684 non-null  float64\n",
      " 2   bath          608684 non-null  float64\n",
      " 3   acre_lot      608684 non-null  float64\n",
      " 4   zip_code      608684 non-null  float64\n",
      " 5   house_size    608684 non-null  float64\n",
      " 6   ppsf_zipcode  608684 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 37.2 MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_house_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "8bdbb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_zipcode(df):\n",
    "    # Convert zip_code column to 5-digit string\n",
    "    df['zip_code'] = df['zip_code'].astype(str).str.replace('\\.0$', '', regex=True).str.zfill(5)\n",
    "\n",
    "    # Get unique zip codes\n",
    "    unique_zips = df['zip_code'].unique()\n",
    "\n",
    "    # Initialize pgeocode for US\n",
    "    nomi = pgeocode.Nominatim('us')\n",
    "\n",
    "    # Function to get coordinates\n",
    "    def get_coordinates(zip_code):\n",
    "        try:\n",
    "            result = nomi.query_postal_code(zip_code)\n",
    "            if result.empty or pd.isna(result.latitude):\n",
    "                return pd.Series([None, None])\n",
    "            return pd.Series([result.latitude, result.longitude])\n",
    "        except:\n",
    "            return pd.Series([None, None])\n",
    "\n",
    "    # Create DataFrame for unique zip codes\n",
    "    zip_coords = pd.DataFrame(unique_zips, columns=['zip_code'])\n",
    "    zip_coords[['latitude', 'longitude']] = zip_coords.apply(lambda row: get_coordinates(row['zip_code']), axis=1)\n",
    "\n",
    "    # Map coordinates back to filtered_house_df\n",
    "    coords_dict = zip_coords.set_index('zip_code')[['latitude', 'longitude']].to_dict('index')\n",
    "    df['latitude'] = df['zip_code'].map(lambda x: coords_dict.get(x, {}).get('latitude'))\n",
    "    df['longitude'] = df['zip_code'].map(lambda x: coords_dict.get(x, {}).get('longitude'))\n",
    "\n",
    "    # Drop 'zip_code' column\n",
    "    df = df.drop(columns=['zip_code'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "c7cb43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert zipcodes to coordinates\n",
    "#cleaned_house_df = convert_zipcode(cleaned_house_df)\n",
    "#cleaned_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "bf20277f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 608684 entries, 0 to 854410\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   price         608684 non-null  float64\n",
      " 1   bed           608684 non-null  float64\n",
      " 2   bath          608684 non-null  float64\n",
      " 3   acre_lot      608684 non-null  float64\n",
      " 4   zip_code      608684 non-null  float64\n",
      " 5   house_size    608684 non-null  float64\n",
      " 6   ppsf_zipcode  608684 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 37.2 MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_house_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "d08eee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features: ['bed', 'bath', 'acre_lot', 'zip_code', 'house_size', 'ppsf_zipcode']\n",
      "Numeric features for scaling: ['bed', 'bath', 'acre_lot', 'house_size', 'ppsf_zipcode']\n",
      "\n",
      "Model Results:\n",
      "XGBoost RMSE: $157,633.43\n",
      "Mean Absolute Error (MAE): $95,198.92\n",
      "RÂ² Score: 0.8281\n",
      "\n",
      "Feature Importance:\n",
      "bed: 0.0175\n",
      "bath: 0.1021\n",
      "acre_lot: 0.0223\n",
      "house_size: 0.3833\n",
      "ppsf_zipcode: 0.4621\n",
      "zip_code: 0.0126\n",
      "\n",
      "Sample of Actual vs. Predicted Prices:\n",
      "        Actual Price  Predicted Price     Difference\n",
      "524430      375000.0    463914.781250  -88914.781250\n",
      "711473      342000.0    399033.906250  -57033.906250\n",
      "730429      510000.0    475309.968750   34690.031250\n",
      "149804     1675000.0    800231.500000  874768.500000\n",
      "74707       475000.0    494328.593750  -19328.593750\n",
      "625130      289500.0    380936.031250  -91436.031250\n",
      "79687       699999.0    893581.250000 -193582.250000\n",
      "532139      770000.0    717525.125000   52474.875000\n",
      "391375      549000.0    471772.656250   77227.343750\n",
      "271014      190000.0    172621.078125   17378.921875\n"
     ]
    }
   ],
   "source": [
    "# Work on a copy to avoid SettingWithCopyWarning\n",
    "df = cleaned_house_df.copy()\n",
    "\n",
    "# Define features and target\n",
    "target = 'price'\n",
    "features = [col for col in df.columns if col != target]  # Exclude price\n",
    "numeric_features = [col for col in features if col != 'zip_code']  # Exclude zip_code\n",
    "\n",
    "# Verify columns\n",
    "print(\"\\nFeatures:\", features)\n",
    "print(\"Numeric features for scaling:\", numeric_features)\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"'{target}' column not found. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Create X and y\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Preprocess with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep zip_code unscaled\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Results:\")\n",
    "print(f\"XGBoost RMSE: ${rmse:,.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_names = numeric_features + ['zip_code']\n",
    "print(\"\\nFeature Importance:\")\n",
    "for name, importance in zip(feature_names, pipeline.named_steps['regressor'].feature_importances_):\n",
    "    print(f\"{name}: {importance:.4f}\")\n",
    "\n",
    "# Sample of actual vs. predicted prices\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual Price': y_test,\n",
    "    'Predicted Price': y_pred,\n",
    "    'Difference': y_test - y_pred\n",
    "})\n",
    "print(\"\\nSample of Actual vs. Predicted Prices:\")\n",
    "print(results_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "07ffc050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â Model saved to: /Users/carlokrups/code/JensKlug/zillows_real_estate/zillow/model/models/20250611-141552_xgboost_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# Define model save path\n",
    "model_dir = \"/Users/carlokrups/code/JensKlug/zillows_real_estate/zillow/model/models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Timestamp for versioning\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_path = os.path.join(model_dir, f\"{timestamp}_xgboost_pipeline.joblib\")\n",
    "\n",
    "# Save pipeline\n",
    "joblib.dump(pipeline, model_path)\n",
    "\n",
    "print(f\"\\nâ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356c67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zillows_real_estate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
