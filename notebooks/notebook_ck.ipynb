{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f06a3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "import pgeocode\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827ca251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read HouseTS.csv into area_df\n",
    "area_df = pd.read_csv('../raw_data/HouseTS.csv')\n",
    "\n",
    "# Read realtor-data.csv into house_df\n",
    "house_df = pd.read_csv('../raw_data/realtor-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17c4ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of unique zipcodes in area_df\n",
    "unique_zipcodes_area_df = area_df['zipcode'].unique().tolist()\n",
    "\n",
    "# Filter house_df by unique_zipcoes_area_df\n",
    "house_df = house_df[house_df['zip_code'].isin(unique_zipcodes_area_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "305d8949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6226"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_zipcodes_area_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0127111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LTM_area_df\n",
    "LTM_area_df = area_df[area_df['date'] == '2023-12-31'].copy()\n",
    "LTM_area_df = LTM_area_df[['Per Capita Income', 'Median Rent', 'zipcode']]\n",
    "\n",
    "# Rename zipcode to zip_code in LTM_area_df\n",
    "LTM_area_df = LTM_area_df.rename(columns={'zipcode': 'zip_code', 'Per Capita Income': 'p_c_income', 'Median Rent': 'median_rent'})\n",
    "\n",
    "# Merge\n",
    "merged_df = house_df.merge(LTM_area_df, on='zip_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "154cda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Drop columns 'brokered_by', 'status'\n",
    "    df = df.drop(columns=['brokered_by', 'status'])\n",
    "\n",
    "     # Drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Drop columns 'street', 'city', 'state' and 'prev_sold_date'\n",
    "    df = df.drop(columns=['street', 'city', 'state', 'prev_sold_date'])\n",
    "\n",
    "    # Drop rows with NaN values from 'price'\n",
    "    df = df.dropna(subset=['price'])\n",
    "\n",
    "    # Create list where 'bed' & 'bath' & 'house_size' are NaN\n",
    "    nan_values = df[\n",
    "        (pd.isna(df['bed'])) &\n",
    "        (pd.isna(df['bath'])) &\n",
    "        (pd.isna(df['house_size']))\n",
    "    ]\n",
    "\n",
    "    # Filter out rows that are in nan_values because we assume they are land sales\n",
    "    df = df[~df.index.isin(nan_values.index)]\n",
    "\n",
    "    # Impute missing data\n",
    "    df['bed'] = df['bed'].fillna(df['bed'].median())\n",
    "    df['bath'] = df['bath'].fillna(df['bath'].median())\n",
    "    df['house_size'] = df['house_size'].fillna(df['house_size'].median())\n",
    "    df['acre_lot'] = df['acre_lot'].fillna(0)\n",
    "\n",
    "    # Step 2: Calculate PPSF for each row\n",
    "    df['ppsf'] = df['price'] / df['house_size']\n",
    "\n",
    "    # Step 3: Calculate median PPSF per zip_code\n",
    "    ppsf_median = df.groupby('zip_code')['ppsf'].median().reset_index(name='ppsf_zipcode')\n",
    "\n",
    "    # Step 4: Merge median PPSF back to df\n",
    "    df = df.merge(ppsf_median, on='zip_code', how='left')\n",
    "\n",
    "    # Drop temporary ppsf column\n",
    "    df = df.drop(columns=['ppsf'])\n",
    "\n",
    "    # Calculate boundaries for 'price', 'acre_lot', 'house_size', 'ppsf_zipcode'\n",
    "    lower_price = df['price'].quantile(0.03)\n",
    "    upper_price = df['price'].quantile(0.97)\n",
    "    upper_house_size = df['house_size'].quantile(0.99)\n",
    "    lower_acre_lot = df['acre_lot'].quantile(0.01)\n",
    "    upper_acre_lot = df['acre_lot'].quantile(0.99)\n",
    "    lower_ppsf_zipcode = df['ppsf_zipcode'].quantile(0.03)\n",
    "    upper_ppsf_zipcode = df['ppsf_zipcode'].quantile(0.97)\n",
    "\n",
    "    # Apply boundaries to df\n",
    "    df = df[\n",
    "        (df['price'] > lower_price) &\n",
    "        (df['price'] < upper_price) &\n",
    "        (df['bed'] < 14) &\n",
    "        (df['bath'] < 12) &\n",
    "        (df['house_size'] < upper_house_size) &\n",
    "        (df['acre_lot'] > lower_acre_lot) &\n",
    "        (df['acre_lot'] < upper_acre_lot) &\n",
    "        (df['ppsf_zipcode'] > lower_ppsf_zipcode) &\n",
    "        (df['ppsf_zipcode'] < upper_ppsf_zipcode) &\n",
    "        (df['median_rent'] > 0) &\n",
    "        (df['p_c_income'] > 0)\n",
    "        ]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56ea42f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean df\n",
    "cleaned_house_df = clean_data(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc6b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 580238 entries, 1 to 854410\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   price         580238 non-null  float64\n",
      " 1   bed           580238 non-null  float64\n",
      " 2   bath          580238 non-null  float64\n",
      " 3   acre_lot      580238 non-null  float64\n",
      " 4   zip_code      580238 non-null  float64\n",
      " 5   house_size    580238 non-null  float64\n",
      " 6   p_c_income    580238 non-null  float64\n",
      " 7   median_rent   580238 non-null  float64\n",
      " 8   ppsf_zipcode  580238 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 44.3 MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_house_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bdbb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_zipcode(df):\n",
    "    # Convert zip_code column to 5-digit string\n",
    "    df['zip_code'] = df['zip_code'].astype(str).str.replace('\\.0$', '', regex=True).str.zfill(5)\n",
    "\n",
    "    # Get unique zip codes\n",
    "    unique_zips = df['zip_code'].unique()\n",
    "\n",
    "    # Initialize pgeocode for US\n",
    "    nomi = pgeocode.Nominatim('us')\n",
    "\n",
    "    # Function to get coordinates\n",
    "    def get_coordinates(zip_code):\n",
    "        try:\n",
    "            result = nomi.query_postal_code(zip_code)\n",
    "            if result.empty or pd.isna(result.latitude):\n",
    "                return pd.Series([None, None])\n",
    "            return pd.Series([result.latitude, result.longitude])\n",
    "        except:\n",
    "            return pd.Series([None, None])\n",
    "\n",
    "    # Create DataFrame for unique zip codes\n",
    "    zip_coords = pd.DataFrame(unique_zips, columns=['zip_code'])\n",
    "    zip_coords[['latitude', 'longitude']] = zip_coords.apply(lambda row: get_coordinates(row['zip_code']), axis=1)\n",
    "\n",
    "    # Map coordinates back to filtered_house_df\n",
    "    coords_dict = zip_coords.set_index('zip_code')[['latitude', 'longitude']].to_dict('index')\n",
    "    df['latitude'] = df['zip_code'].map(lambda x: coords_dict.get(x, {}).get('latitude'))\n",
    "    df['longitude'] = df['zip_code'].map(lambda x: coords_dict.get(x, {}).get('longitude'))\n",
    "\n",
    "    # Drop 'zip_code' column\n",
    "    df = df.drop(columns=['zip_code'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7cb43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert zipcodes to coordinates\n",
    "#cleaned_house_df = convert_zipcode(cleaned_house_df)\n",
    "#cleaned_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf20277f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 580238 entries, 1 to 854410\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   price         580238 non-null  float64\n",
      " 1   bed           580238 non-null  float64\n",
      " 2   bath          580238 non-null  float64\n",
      " 3   acre_lot      580238 non-null  float64\n",
      " 4   zip_code      580238 non-null  float64\n",
      " 5   house_size    580238 non-null  float64\n",
      " 6   p_c_income    580238 non-null  float64\n",
      " 7   median_rent   580238 non-null  float64\n",
      " 8   ppsf_zipcode  580238 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 44.3 MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_house_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d08eee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features: ['bed', 'bath', 'acre_lot', 'zip_code', 'house_size', 'p_c_income', 'ppsf_zipcode']\n",
      "Numeric features for scaling: ['bed', 'bath', 'acre_lot', 'house_size', 'p_c_income', 'ppsf_zipcode']\n",
      "\n",
      "Model Results:\n",
      "XGBoost RMSE: $155,879.16\n",
      "Mean Absolute Error (MAE): $94,014.04\n",
      "R² Score: 0.8346\n",
      "\n",
      "Feature Importance:\n",
      "bed: 0.0164\n",
      "bath: 0.0811\n",
      "acre_lot: 0.0200\n",
      "house_size: 0.3550\n",
      "p_c_income: 0.0215\n",
      "ppsf_zipcode: 0.4933\n",
      "zip_code: 0.0127\n",
      "\n",
      "Sample of Actual vs. Predicted Prices:\n",
      "        Actual Price  Predicted Price     Difference\n",
      "352146      599950.0     5.924202e+05    7529.812500\n",
      "847235      619000.0     6.162546e+05    2745.437500\n",
      "819496      400000.0     3.983023e+05    1697.718750\n",
      "585530      375000.0     4.189242e+05  -43924.250000\n",
      "734283      639000.0     6.945119e+05  -55511.875000\n",
      "242635      229900.0     2.087486e+05   21151.390625\n",
      "135398      173500.0     1.549828e+05   18517.218750\n",
      "131444      359900.0     3.328602e+05   27039.781250\n",
      "851911      525000.0     6.499014e+05 -124901.375000\n",
      "453249     1099000.0     1.123454e+06  -24454.250000\n"
     ]
    }
   ],
   "source": [
    "# Work on a copy to avoid SettingWithCopyWarning\n",
    "df = cleaned_house_df.copy()\n",
    "df = df.drop(columns=['median_rent'])\n",
    "\n",
    "# Define features and target\n",
    "target = 'price'\n",
    "features = [col for col in df.columns if col != target]  # Exclude price\n",
    "numeric_features = [col for col in features if col != 'zip_code']  # Exclude zip_code\n",
    "\n",
    "# Verify columns\n",
    "print(\"\\nFeatures:\", features)\n",
    "print(\"Numeric features for scaling:\", numeric_features)\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"'{target}' column not found. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Create X and y\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Preprocess with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep zip_code unscaled\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Results:\")\n",
    "print(f\"XGBoost RMSE: ${rmse:,.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_names = numeric_features + ['zip_code']\n",
    "print(\"\\nFeature Importance:\")\n",
    "for name, importance in zip(feature_names, pipeline.named_steps['regressor'].feature_importances_):\n",
    "    print(f\"{name}: {importance:.4f}\")\n",
    "\n",
    "# Sample of actual vs. predicted prices\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual Price': y_test,\n",
    "    'Predicted Price': y_pred,\n",
    "    'Difference': y_test - y_pred\n",
    "})\n",
    "print(\"\\nSample of Actual vs. Predicted Prices:\")\n",
    "print(results_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175a292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b973d36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07ffc050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Model saved to: /Users/carlokrups/code/JensKlug/zillows_real_estate/zillow/model/models/20250611-161631_xgboost_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# Define model save path\n",
    "model_dir = \"/Users/carlokrups/code/JensKlug/zillows_real_estate/zillow/model/models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Timestamp for versioning\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_path = os.path.join(model_dir, f\"{timestamp}_xgboost_pipeline.joblib\")\n",
    "\n",
    "# Save pipeline\n",
    "joblib.dump(pipeline, model_path)\n",
    "\n",
    "print(f\"\\n✅ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356c67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zillows_real_estate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
