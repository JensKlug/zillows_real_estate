{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f7e7b-04fb-40dd-9f56-73c7e67254a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T14:22:33.268879Z",
     "iopub.status.busy": "2025-06-10T14:22:33.268763Z",
     "iopub.status.idle": "2025-06-10T14:22:33.455212Z",
     "shell.execute_reply": "2025-06-10T14:22:33.454420Z",
     "shell.execute_reply.started": "2025-06-10T14:22:33.268864Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "import pgeocode\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331c152c-c6eb-4d70-9229-7c374ded6099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T14:22:33.456105Z",
     "iopub.status.busy": "2025-06-10T14:22:33.455852Z",
     "iopub.status.idle": "2025-06-10T14:22:34.583836Z",
     "shell.execute_reply": "2025-06-10T14:22:34.583170Z",
     "shell.execute_reply.started": "2025-06-10T14:22:33.456088Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read HouseTS.csv into area_df\n",
    "area_df = pd.read_csv('../raw_data/HouseTS.csv')\n",
    "\n",
    "# Read realtor-data.csv into house_df\n",
    "house_df = pd.read_csv('../raw_data/realtor-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8822cafa-2d08-4b3c-ac6a-61eb8ebf0967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T14:22:34.585476Z",
     "iopub.status.busy": "2025-06-10T14:22:34.585119Z",
     "iopub.status.idle": "2025-06-10T14:22:34.597243Z",
     "shell.execute_reply": "2025-06-10T14:22:34.596693Z",
     "shell.execute_reply.started": "2025-06-10T14:22:34.585457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create list of unique zipcodes in area_df\n",
    "unique_zipcodes_area_df = area_df['zipcode'].unique().tolist()\n",
    "\n",
    "# Filter house_df by unique_zipcoes_area_df\n",
    "house_df = house_df[house_df['zip_code'].isin(unique_zipcodes_area_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a09e7f-1781-4e8a-9e07-757412072781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T14:22:34.598001Z",
     "iopub.status.busy": "2025-06-10T14:22:34.597852Z",
     "iopub.status.idle": "2025-06-10T14:22:35.907030Z",
     "shell.execute_reply": "2025-06-10T14:22:35.906426Z",
     "shell.execute_reply.started": "2025-06-10T14:22:34.597987Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Drop columns 'brokered_by', 'status'\n",
    "    df = df.drop(columns=['brokered_by', 'status'])\n",
    "\n",
    "     # Drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Drop columns 'street', 'city', 'state' and 'prev_sold_date'\n",
    "    df = df.drop(columns=['street', 'city', 'state', 'prev_sold_date'])\n",
    "\n",
    "    # Drop rows with NaN values from 'price'\n",
    "    df = df.dropna(subset=['price'])\n",
    "\n",
    "    # Create list where 'bed' & 'bath' & 'house_size' are NaN\n",
    "    nan_values = df[\n",
    "        (pd.isna(df['bed'])) &\n",
    "        (pd.isna(df['bath'])) &\n",
    "        (pd.isna(df['house_size']))\n",
    "    ]\n",
    "\n",
    "    # Filter out rows that are in nan_values because we assume they are land sales\n",
    "    df = df[~df.index.isin(nan_values.index)]\n",
    "\n",
    "    # Impute missing data\n",
    "    df['bed'] = df['bed'].fillna(df['bed'].median())\n",
    "    df['bath'] = df['bath'].fillna(df['bath'].median())\n",
    "    df['house_size'] = df['house_size'].fillna(df['house_size'].median())\n",
    "    df['acre_lot'] = df['acre_lot'].fillna(0)\n",
    "\n",
    "    # Step 2: Calculate PPSF for each row\n",
    "    df['ppsf'] = df['price'] / df['house_size']\n",
    "\n",
    "    # Step 3: Calculate median PPSF per zip_code\n",
    "    ppsf_median = df.groupby('zip_code')['ppsf'].median().reset_index(name='ppsf_zipcode')\n",
    "\n",
    "    # Step 4: Merge median PPSF back to df\n",
    "    df = df.merge(ppsf_median, on='zip_code', how='left')\n",
    "\n",
    "    # Drop temporary ppsf column\n",
    "    df = df.drop(columns=['ppsf'])\n",
    "\n",
    "    # Calculate boundaries for 'price', 'acre_lot', 'house_size', 'ppsf_zipcode'\n",
    "    lower_price = df['price'].quantile(0.03)\n",
    "    upper_price = df['price'].quantile(0.97)\n",
    "    upper_house_size = df['house_size'].quantile(0.99)\n",
    "    lower_acre_lot = df['acre_lot'].quantile(0.01)\n",
    "    upper_acre_lot = df['acre_lot'].quantile(0.99)\n",
    "    lower_ppsf_zipcode = df['ppsf_zipcode'].quantile(0.03)\n",
    "    upper_ppsf_zipcode = df['ppsf_zipcode'].quantile(0.97)\n",
    "\n",
    "    # Apply boundaries to df\n",
    "    df = df[\n",
    "        (df['price'] > lower_price) &\n",
    "        (df['price'] < upper_price) &\n",
    "        (df['bed'] < 14) &\n",
    "        (df['bath'] < 12) &\n",
    "        (df['house_size'] < upper_house_size) &\n",
    "        (df['acre_lot'] > lower_acre_lot) &\n",
    "        (df['acre_lot'] < upper_acre_lot) &\n",
    "        (df['ppsf_zipcode'] > lower_ppsf_zipcode) &\n",
    "        (df['ppsf_zipcode'] < upper_ppsf_zipcode)\n",
    "        ]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53975bc0-a71e-4ce0-9ef1-7e45f9d18769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T14:22:35.907756Z",
     "iopub.status.busy": "2025-06-10T14:22:35.907624Z",
     "iopub.status.idle": "2025-06-10T14:22:35.914094Z",
     "shell.execute_reply": "2025-06-10T14:22:35.913513Z",
     "shell.execute_reply.started": "2025-06-10T14:22:35.907744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean df\n",
    "cleaned_house_df = clean_data(house_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43d04d4-09c0-4735-87b5-252ed4863580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T14:22:35.915110Z",
     "iopub.status.busy": "2025-06-10T14:22:35.914925Z",
     "iopub.status.idle": "2025-06-10T14:22:36.201894Z",
     "shell.execute_reply": "2025-06-10T14:22:36.201062Z",
     "shell.execute_reply.started": "2025-06-10T14:22:35.915095Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_zipcode(df):\n",
    "    # Convert zip_code column to 5-digit string\n",
    "    df['zip_code'] = df['zip_code'].astype(str).str.replace('\\.0$', '', regex=True).str.zfill(5)\n",
    "\n",
    "    # Get unique zip codes\n",
    "    unique_zips = df['zip_code'].unique()\n",
    "\n",
    "    # Initialize pgeocode for US\n",
    "    nomi = pgeocode.Nominatim('us')\n",
    "\n",
    "    # Function to get coordinates\n",
    "    def get_coordinates(zip_code):\n",
    "        try:\n",
    "            result = nomi.query_postal_code(zip_code)\n",
    "            if result.empty or pd.isna(result.latitude):\n",
    "                return pd.Series([None, None])\n",
    "            return pd.Series([result.latitude, result.longitude])\n",
    "        except:\n",
    "            return pd.Series([None, None])\n",
    "\n",
    "    # Create DataFrame for unique zip codes\n",
    "    zip_coords = pd.DataFrame(unique_zips, columns=['zip_code'])\n",
    "    zip_coords[['latitude', 'longitude']] = zip_coords.apply(lambda row: get_coordinates(row['zip_code']), axis=1)\n",
    "\n",
    "    # Map coordinates back to filtered_house_df\n",
    "    coords_dict = zip_coords.set_index('zip_code')[['latitude', 'longitude']].to_dict('index')\n",
    "    df['latitude'] = df['zip_code'].map(lambda x: coords_dict.get(x, {}).get('latitude'))\n",
    "    df['longitude'] = df['zip_code'].map(lambda x: coords_dict.get(x, {}).get('longitude'))\n",
    "\n",
    "    # Drop 'zip_code' column\n",
    "    df = df.drop(columns=['zip_code'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c98d6d-a252-4144-a8b1-998e5dd98037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T14:22:36.203043Z",
     "iopub.status.busy": "2025-06-10T14:22:36.202597Z",
     "iopub.status.idle": "2025-06-10T14:22:36.228077Z",
     "shell.execute_reply": "2025-06-10T14:22:36.223684Z",
     "shell.execute_reply.started": "2025-06-10T14:22:36.203019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert zipcodes to coordinates\n",
    "cleaned_house_df = convert_zipcode(cleaned_house_df)\n",
    "#cleaned_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0bded8c-4aab-4f69-ba1a-d4c58d9b204c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T14:22:36.229853Z",
     "iopub.status.busy": "2025-06-10T14:22:36.228746Z",
     "iopub.status.idle": "2025-06-10T14:22:36.584255Z",
     "shell.execute_reply": "2025-06-10T14:22:36.583592Z",
     "shell.execute_reply.started": "2025-06-10T14:22:36.229836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>house_size</th>\n",
       "      <th>ppsf_zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.086840e+05</td>\n",
       "      <td>608684.000000</td>\n",
       "      <td>608684.000000</td>\n",
       "      <td>608684.000000</td>\n",
       "      <td>608684.000000</td>\n",
       "      <td>608684.000000</td>\n",
       "      <td>608684.000000</td>\n",
       "      <td>608684.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.811950e+05</td>\n",
       "      <td>3.423869</td>\n",
       "      <td>2.621621</td>\n",
       "      <td>0.418884</td>\n",
       "      <td>2059.583033</td>\n",
       "      <td>284.782134</td>\n",
       "      <td>36.332211</td>\n",
       "      <td>-95.276863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.807753e+05</td>\n",
       "      <td>1.067719</td>\n",
       "      <td>1.029695</td>\n",
       "      <td>0.914755</td>\n",
       "      <td>916.177339</td>\n",
       "      <td>147.298420</td>\n",
       "      <td>5.403365</td>\n",
       "      <td>17.147978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.152000e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>125.323069</td>\n",
       "      <td>25.284600</td>\n",
       "      <td>-123.633500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.294975e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>180.838951</td>\n",
       "      <td>32.924700</td>\n",
       "      <td>-115.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.750000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>1809.000000</td>\n",
       "      <td>235.627284</td>\n",
       "      <td>34.749000</td>\n",
       "      <td>-93.288600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.999990e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>2476.000000</td>\n",
       "      <td>330.760750</td>\n",
       "      <td>40.404050</td>\n",
       "      <td>-80.414600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.499999e+06</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.990000</td>\n",
       "      <td>6571.000000</td>\n",
       "      <td>952.941176</td>\n",
       "      <td>48.239500</td>\n",
       "      <td>-70.619400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price            bed           bath       acre_lot  \\\n",
       "count  6.086840e+05  608684.000000  608684.000000  608684.000000   \n",
       "mean   5.811950e+05       3.423869       2.621621       0.418884   \n",
       "std    3.807753e+05       1.067719       1.029695       0.914755   \n",
       "min    1.152000e+05       1.000000       1.000000       0.010000   \n",
       "25%    3.294975e+05       3.000000       2.000000       0.120000   \n",
       "50%    4.750000e+05       3.000000       2.000000       0.170000   \n",
       "75%    6.999990e+05       4.000000       3.000000       0.290000   \n",
       "max    2.499999e+06      13.000000      11.000000       9.990000   \n",
       "\n",
       "          house_size   ppsf_zipcode       latitude      longitude  \n",
       "count  608684.000000  608684.000000  608684.000000  608684.000000  \n",
       "mean     2059.583033     284.782134      36.332211     -95.276863  \n",
       "std       916.177339     147.298420       5.403365      17.147978  \n",
       "min       100.000000     125.323069      25.284600    -123.633500  \n",
       "25%      1436.000000     180.838951      32.924700    -115.280100  \n",
       "50%      1809.000000     235.627284      34.749000     -93.288600  \n",
       "75%      2476.000000     330.760750      40.404050     -80.414600  \n",
       "max      6571.000000     952.941176      48.239500     -70.619400  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_house_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8dc2e46-320f-480a-9cf2-88e371fa862c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T14:22:36.585087Z",
     "iopub.status.busy": "2025-06-10T14:22:36.584784Z",
     "iopub.status.idle": "2025-06-10T14:22:36.876081Z",
     "shell.execute_reply": "2025-06-10T14:22:36.875436Z",
     "shell.execute_reply.started": "2025-06-10T14:22:36.585072Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Work on a copy to avoid SettingWithCopyWarning\n",
    "# df = cleaned_house_df.copy()\n",
    "# df = df.drop(columns=['latitude', 'longitude'])\n",
    "\n",
    "# # Define features and target\n",
    "# target = 'price'\n",
    "# features = [col for col in df.columns if col != target]  # Exclude price\n",
    "# numeric_features = [col for col in features if col != 'zip_code']  # Exclude zip_code\n",
    "\n",
    "# # Verify columns\n",
    "# print(\"\\nFeatures:\", features)\n",
    "# print(\"Numeric features for scaling:\", numeric_features)\n",
    "# if target not in df.columns:\n",
    "#     raise ValueError(f\"'{target}' column not found. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "# # Create X and y\n",
    "# X = df[features]\n",
    "# y = df[target]\n",
    "\n",
    "# # Preprocess with ColumnTransformer\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', StandardScaler(), numeric_features)\n",
    "#     ],\n",
    "#     remainder='passthrough'  # Keep zip_code unscaled\n",
    "# )\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create pipeline\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1))\n",
    "# ])\n",
    "\n",
    "# # Train model\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Predict and evaluate\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Calculate metrics\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# # Print results\n",
    "# print(\"\\nModel Results:\")\n",
    "# print(f\"XGBoost RMSE: ${rmse:,.2f}\")\n",
    "# print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "# print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# # Feature importance\n",
    "# feature_names = numeric_features + ['zip_code']\n",
    "# print(\"\\nFeature Importance:\")\n",
    "# for name, importance in zip(feature_names, pipeline.named_steps['regressor'].feature_importances_):\n",
    "#     print(f\"{name}: {importance:.4f}\")\n",
    "\n",
    "# # Sample of actual vs. predicted prices\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual Price': y_test,\n",
    "#     'Predicted Price': y_pred,\n",
    "#     'Difference': y_test - y_pred\n",
    "# })\n",
    "# print(\"\\nSample of Actual vs. Predicted Prices:\")\n",
    "# print(results_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beba8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# # 1. Work on a copy to avoid SettingWithCopyWarning\n",
    "# df = cleaned_house_df.copy()\n",
    "# df = df.drop(columns=['latitude', 'longitude'])\n",
    "\n",
    "# # 2. Define features and target\n",
    "# target = 'price'\n",
    "# features = [col for col in df.columns if col != target]  # Exclude price\n",
    "# numeric_features = [col for col in features if col != 'zip_code']  # Exclude zip_code\n",
    "\n",
    "# # Verify columns\n",
    "# print(\"\\nFeatures:\", features)\n",
    "# print(\"Numeric features for scaling:\", numeric_features)\n",
    "# if target not in df.columns:\n",
    "#     raise ValueError(f\"'{target}' column not found. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "# # 3. Create X and y\n",
    "# X = df[features]\n",
    "# y = df[target]\n",
    "\n",
    "# # 4. Preprocess with ColumnTransformer\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', StandardScaler(), numeric_features)  # Scale numeric features\n",
    "#     ],\n",
    "#     remainder='passthrough'  # Keep zip_code unscaled\n",
    "# )\n",
    "\n",
    "# # 5. Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 6. Create pipeline with XGBoost\n",
    "# pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', XGBRegressor(random_state=42, n_jobs=-1))\n",
    "# ])\n",
    "\n",
    "# # 7. Define hyperparameter grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'regressor__n_estimators': [100, 200],  # Number of trees\n",
    "#     'regressor__learning_rate': [0.01, 0.1],  # Step size for boosting\n",
    "#     'regressor__max_depth': [3, 5],  # Depth of trees\n",
    "#     'regressor__min_child_weight': [1, 3]  # Minimum sum of instance weight needed in a child\n",
    "# }\n",
    "\n",
    "# # 8. Perform GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     pipeline,\n",
    "#     param_grid,\n",
    "#     cv=3,  # 3-fold cross-validation\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     n_jobs=-1,  # Use all cores\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # 9. Fit the model\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 10. Evaluate\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# # Print results\n",
    "# print(\"\\nModel Results:\")\n",
    "# print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "# print(f\"Best cross-validated RMSE: ${np.sqrt(-grid_search.best_score_):,.2f}\")\n",
    "# print(f\"Test RMSE: ${rmse:,.2f}\")\n",
    "# print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "# print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# # 11. Feature importance\n",
    "# feature_names = numeric_features + ['zip_code']\n",
    "# regressor = best_model.named_steps['regressor']\n",
    "# print(\"\\nFeature Importance:\")\n",
    "# for name, importance in zip(feature_names, regressor.feature_importances_):\n",
    "#     print(f\"{name}: {importance:.4f}\")\n",
    "\n",
    "# # 12. Sample of actual vs. predicted prices\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Actual Price': y_test,\n",
    "#     'Predicted Price': y_pred,\n",
    "#     'Difference': y_test - y_pred\n",
    "# })\n",
    "# print(\"\\nSample of Actual vs. Predicted Prices:\")\n",
    "# print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "000e0932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93cea8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features: ['bed', 'bath', 'acre_lot', 'house_size', 'ppsf_zipcode', 'latitude', 'longitude']\n",
      "Numeric features for scaling: ['bed', 'bath', 'acre_lot', 'house_size', 'ppsf_zipcode', 'latitude', 'longitude']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RobustScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 4. Preprocess with ColumnTransformer (using RobustScaler)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[1;32m     21\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     22\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler(), [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m---> 23\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mRobustScaler\u001b[49m(), [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbath\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macre_lot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhouse_size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppsf_zipcode\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m     ],\n\u001b[1;32m     25\u001b[0m     remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 5. Split data\u001b[39;00m\n\u001b[1;32m     28\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RobustScaler' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Work on a copy to avoid SettingWithCopyWarning\n",
    "df = cleaned_house_df.copy()\n",
    "\n",
    "# 2. Define features and target\n",
    "target = 'price'\n",
    "features = [col for col in df.columns if col != target]  # Exclude price\n",
    "numeric_features = [col for col in features if col != 'zip_code']  # Exclude zip_code\n",
    "\n",
    "# Verify columns\n",
    "print(\"\\nFeatures:\", features)\n",
    "print(\"Numeric features for scaling:\", numeric_features)\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"'{target}' column not found. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "# 3. Create X and y\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# 4. Preprocess with ColumnTransformer (using RobustScaler)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('std', StandardScaler(), ['latitude', 'longitude']),\n",
    "        ('rob', RobustScaler(), ['bed', 'bath', 'acre_lot', 'house_size', 'ppsf_zipcode'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "# 5. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,)\n",
    "\n",
    "# 6. Create pipeline with XGBoost\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# 7. Define hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200],  # Number of trees\n",
    "    'regressor__learning_rate': [0.01, 0.1],  # Step size for boosting\n",
    "    'regressor__max_depth': [3, 5],  # Depth of trees\n",
    "    'regressor__min_child_weight': [1, 3]  # Minimum sum of instance weight needed in a child\n",
    "}\n",
    "\n",
    "# 8. Perform GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,  # 3-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,  # Use all cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 9. Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 10. Evaluate\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Results:\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validated RMSE: ${np.sqrt(-grid_search.best_score_):,.2f}\")\n",
    "print(f\"Test RMSE: ${rmse:,.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# 11. Feature importance\n",
    "feature_names = numeric_features + ['zip_code']\n",
    "regressor = best_model.named_steps['regressor']\n",
    "print(\"\\nFeature Importance:\")\n",
    "for name, importance in zip(feature_names, regressor.feature_importances_):\n",
    "    print(f\"{name}: {importance:.4f}\")\n",
    "\n",
    "# 12. Sample of actual vs. predicted prices\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual Price': y_test,\n",
    "    'Predicted Price': y_pred,\n",
    "    'Difference': y_test - y_pred\n",
    "})\n",
    "print(\"\\nSample of Actual vs. Predicted Prices:\")\n",
    "print(results_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zillows_real_estate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
