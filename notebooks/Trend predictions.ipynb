{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e062bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7d529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jensk/code/JensKlug/zillows_real_estate/raw_data/HouseTS.csv')\n",
    "\n",
    "df = df.sort_values(['city', 'zipcode', 'date']).reset_index(drop=True)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "train = df[df.date.dt.year<2023]\n",
    "test = df[df.date.dt.year>2022]\n",
    "\n",
    "grouped_train = train.groupby(['city', 'zipcode'])\n",
    "grouped_test = test.groupby(['city', 'zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d78755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nts_train = pd.DataFrame()\\nts_test = pd.DataFrame()\\n\\n\\nls = [1,3,6,12]\\n\\ni = 2\\n\\n#for i in ls:\\nts_train[f'target_profitable_{i}m'] = (grouped_train['price'].shift(-i) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\\nts_train['zipcode'] = grouped_train['zipcode'].shift(0).astype('object') # but remains still an integer...\\n\\n\\nnumeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\\n\\nfor feature in numeric_column_names:\\n    for lag in range(1, 4):  # 1 to 3 months\\n        ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ts_train = pd.DataFrame()\n",
    "ts_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "ls = [1,3,6,12]\n",
    "\n",
    "i = 2\n",
    "\n",
    "#for i in ls:\n",
    "ts_train[f'target_profitable_{i}m'] = (grouped_train['price'].shift(-i) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\n",
    "ts_train['zipcode'] = grouped_train['zipcode'].shift(0).astype('object') # but remains still an integer...\n",
    "\n",
    "\n",
    "numeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "for feature in numeric_column_names:\n",
    "    for lag in range(1, 4):  # 1 to 3 months\n",
    "        ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f574d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts_train #type(ts_train['zipcode'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c097ef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38992/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
      "/tmp/ipykernel_38992/2567415700.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n"
     ]
    }
   ],
   "source": [
    "ts_train = pd.DataFrame()\n",
    "ts_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "ls = [1,3,6,12]\n",
    "\n",
    "i = 1\n",
    "\n",
    "#for i in ls:\n",
    "ts_train[f'target_profitable_{i}m'] = (grouped_train['price'].shift(-i) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\n",
    "ts_train['zipcode'] = grouped_train['zipcode'].shift(0)# .astype('object') # but remains still an integer...\n",
    "numeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "for feature in numeric_column_names:\n",
    "    for lag in range(1, 4):  # 1 to 3 months\n",
    "        ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
    "\n",
    "ts_train = ts_train.dropna().reset_index(drop=True)\n",
    "\n",
    "X_train = ts_train.drop(columns=[f'target_profitable_{i}m'])\n",
    "y_train = ts_train[f'target_profitable_{i}m']\n",
    "\n",
    "\n",
    "ts_test[f'target_profitable_{i}m'] = (grouped_test['price'].shift(-i) > 1.02 * grouped_test['price'].shift(0)).astype(int)\n",
    "ts_test['zipcode'] = grouped_test['zipcode'].shift(0)# .astype('object') # but remains still an integer...\n",
    "numeric_column_names = test.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "for feature in numeric_column_names:\n",
    "    for lag in range(1, 4):  # 1 to 6 months\n",
    "        ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
    "\n",
    "ts_test = ts_test.dropna().reset_index(drop=True)\n",
    "\n",
    "X_test = ts_test.drop(columns=[f'target_profitable_{i}m'])\n",
    "y_test = ts_test[f'target_profitable_{i}m']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = SGDClassifier(loss='log_loss')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "np.savetxt(f\"output_{i}m.csv\", y_pred, delimiter=\",\", header=f\"target_-{i}m\", comments='')\n",
    "\n",
    "del y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b76b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02156683, 0.02597561, 0.02658537, ..., 0.05724137, 0.05721158,\n",
       "        0.05728003],\n",
       "       [0.02512195, 0.02156683, 0.02597561, ..., 0.05750982, 0.05724137,\n",
       "        0.05721158],\n",
       "       [0.0254878 , 0.02512195, 0.02156683, ..., 0.05800361, 0.05750982,\n",
       "        0.05724137],\n",
       "       ...,\n",
       "       [0.02194878, 0.02136585, 0.02195122, ..., 0.05088406, 0.0506083 ,\n",
       "        0.05018581],\n",
       "       [0.02195122, 0.02194878, 0.02136585, ..., 0.05116756, 0.05088406,\n",
       "        0.0506083 ],\n",
       "       [0.02292683, 0.02195122, 0.02194878, ..., 0.05140295, 0.05116756,\n",
       "        0.05088406]], shape=(56034, 108))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8787f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jensk/code/JensKlug/zillows_real_estate/notebooks'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d2a9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_-1m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56029</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56030</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56031</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56032</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56033</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56034 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_-1m\n",
       "0             0.0\n",
       "1             0.0\n",
       "2             0.0\n",
       "3             0.0\n",
       "4             0.0\n",
       "...           ...\n",
       "56029         0.0\n",
       "56030         0.0\n",
       "56031         0.0\n",
       "56032         0.0\n",
       "56033         0.0\n",
       "\n",
       "[56034 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1 = pd.read_csv('output_1m.csv')\n",
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1ad6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_-2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56029</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56030</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56031</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56032</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56033</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56034 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_-2m\n",
       "0             0.0\n",
       "1             0.0\n",
       "2             0.0\n",
       "3             0.0\n",
       "4             0.0\n",
       "...           ...\n",
       "56029         0.0\n",
       "56030         0.0\n",
       "56031         0.0\n",
       "56032         0.0\n",
       "56033         0.0\n",
       "\n",
       "[56034 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2 = pd.read_csv('output_2m.csv')\n",
    "output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ba0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_-1m</th>\n",
       "      <th>target_-2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56029</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56030</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56031</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56032</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56033</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_-1m  target_-2m\n",
       "0             0.0         0.0\n",
       "1             0.0         0.0\n",
       "2             0.0         0.0\n",
       "3             0.0         0.0\n",
       "4             0.0         0.0\n",
       "...           ...         ...\n",
       "56029         0.0         0.0\n",
       "56030         0.0         0.0\n",
       "56031         0.0         0.0\n",
       "56032         0.0         0.0\n",
       "56033         0.0         0.0\n",
       "\n",
       "[56034 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.concat([output_1, output_2], axis=1)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a6087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ts_train = pd.DataFrame()\\nts_test = pd.DataFrame()\\n\\n#ls = [1,3,6,12]\\n\\n\\n\\n#for i in ls:\\nts_train['target_profitable_3m'] = (grouped_train['price'].shift(-6) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\\n\\nnumeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\\n\\nfor feature in numeric_column_names:\\n    for lag in range(1, 4):  # 1 to 3 months\\n        ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\\n\\nts_train = ts_train.dropna().reset_index(drop=True)\\n\\nX_train = ts_train.drop(columns=['target_profitable_3m'])\\ny_train = ts_train['target_profitable_3m']\\n\\n\\nts_test['target_profitable_3m'] = (grouped_test['price'].shift(-6) > 1.02 * grouped_test['price'].shift(0)).astype(int)\\n\\nnumeric_column_names = test.select_dtypes(include='number').columns # drop the lags of zipcode\\n\\nfor feature in numeric_column_names:\\n    for lag in range(1, 4):  # 1 to 6 months\\n        ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\\n\\nts_test = ts_test.dropna().reset_index(drop=True)\\n\\nX_test = ts_test.drop(columns=['target_profitable_3m'])\\ny_test = ts_test['target_profitable_3m']\\n\\nscaler = MinMaxScaler()\\nscaler.fit(X_train)\\nX_train_scaled = scaler.transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\nmodel = SGDClassifier(loss='log_loss')\\nmodel.fit(X_train_scaled, y_train)\\n\\ny_pred = model.predict(X_test_scaled)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ts_train = pd.DataFrame()\n",
    "ts_test = pd.DataFrame()\n",
    "\n",
    "#ls = [1,3,6,12]\n",
    "\n",
    "\n",
    "\n",
    "#for i in ls:\n",
    "ts_train['target_profitable_3m'] = (grouped_train['price'].shift(-6) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\n",
    "\n",
    "numeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "for feature in numeric_column_names:\n",
    "    for lag in range(1, 4):  # 1 to 3 months\n",
    "        ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
    "\n",
    "ts_train = ts_train.dropna().reset_index(drop=True)\n",
    "\n",
    "X_train = ts_train.drop(columns=['target_profitable_3m'])\n",
    "y_train = ts_train['target_profitable_3m']\n",
    "\n",
    "\n",
    "ts_test['target_profitable_3m'] = (grouped_test['price'].shift(-6) > 1.02 * grouped_test['price'].shift(0)).astype(int)\n",
    "\n",
    "numeric_column_names = test.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "for feature in numeric_column_names:\n",
    "    for lag in range(1, 4):  # 1 to 6 months\n",
    "        ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
    "\n",
    "ts_test = ts_test.dropna().reset_index(drop=True)\n",
    "\n",
    "X_test = ts_test.drop(columns=['target_profitable_3m'])\n",
    "y_test = ts_test['target_profitable_3m']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = SGDClassifier(loss='log_loss')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ts_train = pd.DataFrame()\\nts_test = pd.DataFrame()\\n\\n\\nls = [1,3,6,12]\\n\\nfor i in ls:\\n    ts_train[f\\'target_profitable_{i}m\\'] = (grouped_train[\\'price\\'].shift(-i) > 1.02 * grouped_train[\\'price\\'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\\n\\n    numeric_column_names = train.select_dtypes(include=\\'number\\').columns # drop the lags of zipcode\\n\\n    for feature in numeric_column_names:\\n        for lag in range(1, 4):  # 1 to 3 months\\n            ts_train[f\\'{feature}_{lag}m\\'] = grouped_train[f\\'{feature}\\'].shift(lag)\\n\\n    ts_train = ts_train.dropna().reset_index(drop=True)\\n\\n    X_train = ts_train.drop(columns=[f\\'target_profitable_{i}m\\'])\\n    y_train = ts_train[f\\'target_profitable_{i}m\\']\\n\\n\\n    ts_test[f\\'target_profitable_{i}m\\'] = (grouped_test[\\'price\\'].shift(-i) > 1.02 * grouped_test[\\'price\\'].shift(0)).astype(int)\\n\\n    numeric_column_names = test.select_dtypes(include=\\'number\\').columns # drop the lags of zipcode\\n\\n    for feature in numeric_column_names:\\n        for lag in range(1, 4):  # 1 to 6 months\\n            ts_test[f\\'{feature}_{lag}m\\'] = grouped_test[f\\'{feature}\\'].shift(lag)\\n\\n    ts_test = ts_test.dropna().reset_index(drop=True)\\n\\n    X_test = ts_test.drop(columns=[f\\'target_profitable_{i}m\\'])\\n    y_test = ts_test[f\\'target_profitable_{i}m\\']\\n\\n    scaler = MinMaxScaler()\\n    scaler.fit(X_train)\\n    X_train_scaled = scaler.transform(X_train)\\n    X_test_scaled = scaler.transform(X_test)\\n\\n    model = SGDClassifier(loss=\\'log_loss\\')\\n    model.fit(X_train_scaled, y_train)\\n\\n    y_pred = model.predict(X_test_scaled)\\n\\n    np.savetxt(f\"output_{i}m.csv\", y_pred, delimiter=\",\", header=f\"target_-{i}m\", comments=\\'\\')\\n\\n    del y_pred\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ts_train = pd.DataFrame()\n",
    "ts_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "ls = [1,3,6,12]\n",
    "\n",
    "for i in ls:\n",
    "    ts_train[f'target_profitable_{i}m'] = (grouped_train['price'].shift(-i) > 1.02 * grouped_train['price'].shift(0)).astype(int) # We fail to exclude the last three obervastions since with the shaft they are NaN!\n",
    "\n",
    "    numeric_column_names = train.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "    for feature in numeric_column_names:\n",
    "        for lag in range(1, 4):  # 1 to 3 months\n",
    "            ts_train[f'{feature}_{lag}m'] = grouped_train[f'{feature}'].shift(lag)\n",
    "\n",
    "    ts_train = ts_train.dropna().reset_index(drop=True)\n",
    "\n",
    "    X_train = ts_train.drop(columns=[f'target_profitable_{i}m'])\n",
    "    y_train = ts_train[f'target_profitable_{i}m']\n",
    "\n",
    "\n",
    "    ts_test[f'target_profitable_{i}m'] = (grouped_test['price'].shift(-i) > 1.02 * grouped_test['price'].shift(0)).astype(int)\n",
    "\n",
    "    numeric_column_names = test.select_dtypes(include='number').columns # drop the lags of zipcode\n",
    "\n",
    "    for feature in numeric_column_names:\n",
    "        for lag in range(1, 4):  # 1 to 6 months\n",
    "            ts_test[f'{feature}_{lag}m'] = grouped_test[f'{feature}'].shift(lag)\n",
    "\n",
    "    ts_test = ts_test.dropna().reset_index(drop=True)\n",
    "\n",
    "    X_test = ts_test.drop(columns=[f'target_profitable_{i}m'])\n",
    "    y_test = ts_test[f'target_profitable_{i}m']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = SGDClassifier(loss='log_loss')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    np.savetxt(f\"output_{i}m.csv\", y_pred, delimiter=\",\", header=f\"target_-{i}m\", comments='')\n",
    "\n",
    "    del y_pred\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zillows_real_estate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
